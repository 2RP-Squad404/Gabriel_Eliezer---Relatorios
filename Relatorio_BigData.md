# Relatório de Estudos

**Nome do Estagiário:** [Gabriel Eliezer Rodrigues]  
**Data:** [08/08/2024]
**Data:** [09/08/2024]


## Assuntos Vistos

- [Big Data]
- [Banco de Dados]
- [Escalabilidade H-V]
- [MapReduce]
- [Hadoop]


## O Que Entendi
Big Data é um conceito que envolve a coleta, o armazenamento e a análise de grandes volumes de dados provenientes de diversas fontes, desde sensores industriais que monitoram 
máquinas até imagens postadas por pessoas na internet. Esses dados podem ser monitorados e analisados para obter insights valiosos. Por exemplo, o monitoramento dos sensores de
uma máquina pode revelar uma vibração anormal, indicando a necessidade de substituição de uma peça ou orientando o manutentor sobre como agir para reduzir o tempo de
inatividade da máquina. Praticamente tudo pode se tornar um dado útil. Quando postamos uma foto, estamos gerando um dado que pode ser analisado. Com o uso de técnicas avançadas
de engenharia de dados, é possível extrair informações significativas desses dados.

  
## O que é?

As grandes empresas possuem bancos de dados que geram dados a cada momento. Por exemplo, o Facebook, onde cada postagem de foto gera um dado adicional para o banco de dados 
da plataforma. O conceito de Big Data surge como uma forma de generalizar e gerenciar esses dados gerados por grandes empresas. Big Data envolve as técnicas e ferramentas para
trabalhar com esses dados massivos. Isso inclui desde a otimização de processos, como melhorar a performance de servidores para processar dados de maneira mais rápida, até o
aumento da quantidade de computadores para reduzir o peso do tráfego em uma máquina e, consequentemente, melhorar o desempenho de todo o sistema.

Os dados no Big Data são caracterizados por um conceito chamado dos 5V's:

**Velocidade:** Os dados são gerados em alta velocidade, e para serem transformados em informações valiosas, precisam ser processados rapidamente. Embora dados antigos 
também possam conter informações importantes, a coleta de dados em tempo real, através de sensores, contadores inteligentes e celulares, está impulsionando a necessidade 
de lidar com grandes quantidades de dados em tempo real ou quase em tempo real.

**Volume:** Enormes quantidades de dados são geradas a cada minuto por diversas fontes, como:

    > Dispositivos: sensores, IoT, comunicação de máquina a máquina.
    
    >Pessoas: Localização em tempo real, meios de transporte utilizados, aplicações visitadas na web, preferências alimentares preferências musicais, redes sociais, entre 
    outros.
    Estima-se que, em âmbito mundial, o volume de informações produzidas dobre a cada 18 meses.
    
    >Variedade: Existe uma grande diversidade de dados gerados, o que gera um grande desafio no Big Data: como trabalhar com uma quantidade tão vasta de dados e em formatos
    variados. Os dados são gerados em diversos formatos, como:

**Estruturados:** Númericos em banco de dados tradicional.

**Não estruturados:** Como documentos de texto, e-mails, vídeos, áudios, dados de cotações de bolsa e transações financeiras.

**Veracidade:** É essencial garantir que os dados gerados sejam autênticos e verdadeiros. Vale lembrar que nem tudo que aparece em redes sociais é confiável, e dispositivos de
medição podem apresentar erros e falhas.

**Valor:** Este pilar é fundamental. Se os dados não geram valor, os conceitos acima mencionados não teriam relevância. É crucial garantir que os dados analisados sejam úteis 
para a tomada de decisões nos negócios. Em um projeto de Big Data, é de extrema importância ter um objetivo claro para os dados que serão filtrados.



## MapReduce

O MapReduce foi criado pelo Google em 2004 para trabalhar com grandes quantidades de dados.
  MapReduce é uma técnica para trabalhar com grandes quantidades de dados. Como o nome sugere, ela permite reduzir a quantidade de dados em um conjunto de dados menor e
mais manejável. Essa técnica pode ser aplicada com o auxílio do framework Hadoop, que inclui a ferramenta Hadoop MapReduce. É possível encadear sequências de MapReduce,
 bem como executar vários MapReduce em paralelo.


## MapReduce Encadeado(Chained MapReduce)
![image](https://github.com/user-attachments/assets/7f5ff48e-77c3-4beb-bae3-dd34b65c4f6b)



## Processo MapReduce:
![image](https://github.com/user-attachments/assets/67b6f606-1117-42a3-9eff-4bc097ed92d5)



## Links Utilizados (se houver)

- [Udemy](https://www.udemy.com/course/engenheiro-de-dados/learn/lecture/34023182#overview)
- [Estante de Livros Senai](https://estantedelivros.senai.br/view/1T2Fo7Pq5Nr1KA2QtqBQXuZR3-TEJgdns)

  

**Módulos/Etapas Feitas:**  
1. **[Módulo/Etapa 1]:** Bancos de Dados, Big Data, Escalabilidade Horizontal e Vertical.
2. **[Módulo/Etapa 2]:** 5V's, Dados estruturados e Não estruturados, HDFS, MapReduce.

**Recursos Utilizados:**  
Foram utilizados cursos da Udemy como base e também a estante virtual do senai Livro "Big Data e Analytics"


**Desafios Encontrados:**  
Como nas outras trilhas encontrei alguns conteúdos que tive alguma dificuldade para entender no começo porém eu li algumas vezes e assisti videos para entender melhor e assim consegui tirar minhas duvidas, também usei IA para tirar algumas duvidas que surgiram, a IA da estante virtual consegue tirar dúvidas relacionadas ao livro que eu estiver lendo, isso foi de grande ajuda.

**Próximos Passos:**  
Concluir o curso de Big Data da Udemy e ler o restante do Livro.
